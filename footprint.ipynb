{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cc691f-9f16-4804-bb56-67bce7a5edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc26f30-4f14-44a6-a589-7184e0aa7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for dataset\n",
    "train_dir = 'cropped_imgs/train'\n",
    "test_dir = 'cropped_imgs/test'\n",
    "eval_dir = 'cropped_imgs/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fbcc75-5bbf-49dd-8c2e-7daa63f03c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size for resizing\n",
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b85c45-dbdb-410d-bca5-9c73ffad50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize the images\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31942410-14e9-4a7d-af77-91c9a5c67863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2514 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)  # Only rescaling for test data\n",
    "\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'binary' if it's a binary classification task\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced1c825-3fd6-4242-8d7a-b64a1936e791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 719 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen_test.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'binary' if it's a binary classification task\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f32694a-e639-4729-ba9a-749656526228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Choose a pre-trained model (EfficientNetB0 for better performance)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers for initial training\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673dc062-0751-4acb-ac0f-6b775fcc94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Regularization to avoid overfitting\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Adjust for number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed05b273-56ab-4cb2-9f1f-a99d2d43a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using a powerful optimizer (AdamW)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8fb6ff-7719-4a1b-bbcd-a176322bea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Callbacks for Early Stopping and Learning Rate Scheduling\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1781f509-3bf9-4ec4-8b98-86ae66a70bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 661ms/step - accuracy: 0.1019 - loss: 2.8475 - val_accuracy: 0.1099 - val_loss: 2.8067 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 611ms/step - accuracy: 0.1126 - loss: 2.8205 - val_accuracy: 0.1099 - val_loss: 2.8040 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 603ms/step - accuracy: 0.1255 - loss: 2.8050 - val_accuracy: 0.1099 - val_loss: 2.8008 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 606ms/step - accuracy: 0.1178 - loss: 2.8116 - val_accuracy: 0.1099 - val_loss: 2.7997 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 606ms/step - accuracy: 0.1106 - loss: 2.8147 - val_accuracy: 0.1099 - val_loss: 2.8025 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 604ms/step - accuracy: 0.1292 - loss: 2.7995 - val_accuracy: 0.1099 - val_loss: 2.8001 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 609ms/step - accuracy: 0.1249 - loss: 2.8179 - val_accuracy: 0.1099 - val_loss: 2.8037 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 605ms/step - accuracy: 0.1322 - loss: 2.7985 - val_accuracy: 0.1099 - val_loss: 2.7979 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 604ms/step - accuracy: 0.1185 - loss: 2.8052 - val_accuracy: 0.1099 - val_loss: 2.8013 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 605ms/step - accuracy: 0.1247 - loss: 2.8001 - val_accuracy: 0.1099 - val_loss: 2.8004 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 599ms/step - accuracy: 0.1226 - loss: 2.7992 - val_accuracy: 0.1099 - val_loss: 2.8012 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 607ms/step - accuracy: 0.1316 - loss: 2.8015 - val_accuracy: 0.1099 - val_loss: 2.7987 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 600ms/step - accuracy: 0.1179 - loss: 2.8177 - val_accuracy: 0.1099 - val_loss: 2.7989 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 608ms/step - accuracy: 0.1286 - loss: 2.7929 - val_accuracy: 0.1099 - val_loss: 2.7999 - learning_rate: 5.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 607ms/step - accuracy: 0.1187 - loss: 2.8006 - val_accuracy: 0.1099 - val_loss: 2.7995 - learning_rate: 5.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 600ms/step - accuracy: 0.1196 - loss: 2.8104 - val_accuracy: 0.1099 - val_loss: 2.8001 - learning_rate: 5.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 610ms/step - accuracy: 0.1234 - loss: 2.7969 - val_accuracy: 0.1099 - val_loss: 2.8004 - learning_rate: 5.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 607ms/step - accuracy: 0.1268 - loss: 2.8016 - val_accuracy: 0.1099 - val_loss: 2.8000 - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,  # Keep epochs high for full training\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49ea203c-0ddc-47ab-beea-096499bb2d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Fine-tune the base model\n",
    "base_model.trainable = True  # Unfreeze base model layers\n",
    "for layer in base_model.layers[:100]:  # Fine-tune top 100 layers\n",
    "    layer.trainable = False  # Freeze the first few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20c67ee-14d8-412e-94d3-712b3bf569f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-compile the model to apply changes\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "207b8332-0965-42d3-bd7c-baeaeb34bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 927ms/step - accuracy: 0.0496 - loss: 2.9733 - val_accuracy: 0.1057 - val_loss: 2.8160 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1035 - loss: 2.8704 - val_accuracy: 0.0987 - val_loss: 2.8549 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 940ms/step - accuracy: 0.1047 - loss: 2.8227 - val_accuracy: 0.0334 - val_loss: 2.8730 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 940ms/step - accuracy: 0.1227 - loss: 2.8160 - val_accuracy: 0.1168 - val_loss: 2.8620 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1291 - loss: 2.7611 - val_accuracy: 0.1224 - val_loss: 2.8502 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 940ms/step - accuracy: 0.1223 - loss: 2.7731 - val_accuracy: 0.1433 - val_loss: 2.8238 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 932ms/step - accuracy: 0.1378 - loss: 2.7478 - val_accuracy: 0.1238 - val_loss: 2.7991 - learning_rate: 5.0000e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 938ms/step - accuracy: 0.1395 - loss: 2.7241 - val_accuracy: 0.1252 - val_loss: 2.7744 - learning_rate: 5.0000e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 928ms/step - accuracy: 0.1460 - loss: 2.7249 - val_accuracy: 0.1266 - val_loss: 2.7684 - learning_rate: 5.0000e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 928ms/step - accuracy: 0.1382 - loss: 2.7328 - val_accuracy: 0.1266 - val_loss: 2.7629 - learning_rate: 5.0000e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 937ms/step - accuracy: 0.1513 - loss: 2.7268 - val_accuracy: 0.1266 - val_loss: 2.7573 - learning_rate: 5.0000e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 924ms/step - accuracy: 0.1347 - loss: 2.7216 - val_accuracy: 0.1335 - val_loss: 2.7413 - learning_rate: 5.0000e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 943ms/step - accuracy: 0.1489 - loss: 2.7006 - val_accuracy: 0.1335 - val_loss: 2.7382 - learning_rate: 5.0000e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 926ms/step - accuracy: 0.1624 - loss: 2.6863 - val_accuracy: 0.1363 - val_loss: 2.7431 - learning_rate: 5.0000e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 927ms/step - accuracy: 0.1395 - loss: 2.7067 - val_accuracy: 0.1419 - val_loss: 2.7356 - learning_rate: 5.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 939ms/step - accuracy: 0.1646 - loss: 2.6777 - val_accuracy: 0.1474 - val_loss: 2.7428 - learning_rate: 5.0000e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 937ms/step - accuracy: 0.1458 - loss: 2.6888 - val_accuracy: 0.1488 - val_loss: 2.7418 - learning_rate: 5.0000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 945ms/step - accuracy: 0.1594 - loss: 2.6697 - val_accuracy: 0.1516 - val_loss: 2.7221 - learning_rate: 5.0000e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 930ms/step - accuracy: 0.1555 - loss: 2.6809 - val_accuracy: 0.1558 - val_loss: 2.7213 - learning_rate: 5.0000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 938ms/step - accuracy: 0.1583 - loss: 2.6714 - val_accuracy: 0.1419 - val_loss: 2.7232 - learning_rate: 5.0000e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 933ms/step - accuracy: 0.1592 - loss: 2.6876 - val_accuracy: 0.1460 - val_loss: 2.7355 - learning_rate: 5.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1667 - loss: 2.6453 - val_accuracy: 0.1238 - val_loss: 2.7654 - learning_rate: 5.0000e-06\n",
      "Epoch 23/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 940ms/step - accuracy: 0.1636 - loss: 2.6920 - val_accuracy: 0.1433 - val_loss: 2.7248 - learning_rate: 5.0000e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 927ms/step - accuracy: 0.1827 - loss: 2.6482 - val_accuracy: 0.1266 - val_loss: 2.7480 - learning_rate: 5.0000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 942ms/step - accuracy: 0.1684 - loss: 2.6389 - val_accuracy: 0.1405 - val_loss: 2.7163 - learning_rate: 2.5000e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1566 - loss: 2.6659 - val_accuracy: 0.1349 - val_loss: 2.7388 - learning_rate: 2.5000e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1609 - loss: 2.6338 - val_accuracy: 0.1377 - val_loss: 2.7363 - learning_rate: 2.5000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 942ms/step - accuracy: 0.1543 - loss: 2.6560 - val_accuracy: 0.1419 - val_loss: 2.7337 - learning_rate: 2.5000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 936ms/step - accuracy: 0.1680 - loss: 2.6766 - val_accuracy: 0.1405 - val_loss: 2.7263 - learning_rate: 2.5000e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 931ms/step - accuracy: 0.1818 - loss: 2.6218 - val_accuracy: 0.1335 - val_loss: 2.7290 - learning_rate: 2.5000e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 939ms/step - accuracy: 0.1759 - loss: 2.6327 - val_accuracy: 0.1419 - val_loss: 2.7226 - learning_rate: 1.2500e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 929ms/step - accuracy: 0.1644 - loss: 2.6465 - val_accuracy: 0.1419 - val_loss: 2.7243 - learning_rate: 1.2500e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 928ms/step - accuracy: 0.1704 - loss: 2.6422 - val_accuracy: 0.1433 - val_loss: 2.7200 - learning_rate: 1.2500e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 944ms/step - accuracy: 0.1591 - loss: 2.6428 - val_accuracy: 0.1391 - val_loss: 2.7292 - learning_rate: 1.2500e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 934ms/step - accuracy: 0.1595 - loss: 2.6533 - val_accuracy: 0.1335 - val_loss: 2.7400 - learning_rate: 1.2500e-06\n"
     ]
    }
   ],
   "source": [
    "# Train again to fine-tune the model\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,  # Continue training for additional epochs\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311f4d09-27bc-4c49-9299-16c0949ae47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 346 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model\n",
    "eval_generator = datagen_test.flow_from_directory(\n",
    "    eval_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Use 'binary' if it's a binary classification task\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f71ad74-ba67-4c69-87ee-067efc1cf688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 356ms/step - accuracy: 0.2201 - loss: 2.6270\n",
      "Final Evaluation Loss: 2.690399646759033, Final Evaluation Accuracy: 0.17052023112773895\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(eval_generator)\n",
    "print(f\"Final Evaluation Loss: {eval_loss}, Final Evaluation Accuracy: {eval_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8b3b7-0e23-4162-a3a9-9d43d3c05ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
